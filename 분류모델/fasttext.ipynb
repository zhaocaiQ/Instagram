{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882c204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from konlpy.tag import Hannanum\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "import eunjeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4280c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#미술관,박물관\n",
    "with open('corpus/NM.json','r') as f:\n",
    "    nm=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e208ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#식물, 꽃관련\n",
    "with open('corpus/NP.json','r') as f:\n",
    "    np=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac2d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#연극, 극장\n",
    "with open('corpus/NT.json','r') as f:\n",
    "    nt=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c9a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#술집\n",
    "with open('corpus/NA.json','r') as f:\n",
    "    na=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73265f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#카페\n",
    "with open('corpus/NC.json','r') as f:\n",
    "    nc=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c3fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#음식\n",
    "with open('corpus/TF.json','r') as f:\n",
    "    tf=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706eefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_text = []\n",
    "b = [x for x in nm]\n",
    "for i in b:\n",
    "    nm_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491a4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_text = []\n",
    "b = [x for x in np]\n",
    "for i in b:\n",
    "    np_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d862939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_text = []\n",
    "b = [x for x in nt]\n",
    "for i in b:\n",
    "    nt_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a7bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_text = []\n",
    "b = [x for x in na]\n",
    "for i in b:\n",
    "    na_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f46d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_text = []\n",
    "b = [x for x in nc]\n",
    "for i in b:\n",
    "    nc_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a672e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_text = []\n",
    "b = [x for x in tf]\n",
    "for i in b:\n",
    "    tf_text.append(i['document']['content']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9528cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nm_df = pd.DataFrame(nm_text, columns=['text'])\n",
    "nm_df['target']=0\n",
    "np_df = pd.DataFrame(np_text, columns=['text'])\n",
    "np_df['target']=1\n",
    "nt_df = pd.DataFrame(nt_text, columns=['text'])\n",
    "nt_df['target']=2\n",
    "na_df = pd.DataFrame(na_text, columns=['text'])\n",
    "na_df['target']=3\n",
    "nc_df = pd.DataFrame(nc_text, columns=['text'])\n",
    "nc_df['target']=4\n",
    "tf_df = pd.DataFrame(tf_text, columns=['text'])\n",
    "tf_df['target']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36819feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[전시회] 비욘더로드: 과몰입형, 출구없는 전시회이머시브 전시로 소문이 자자했던 비...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부천 가볼만한 전시회 심곡천 네모 갤러리에 다녀왔어요부천 가볼만한 전시회심곡천 네모...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>관람객이면서 동시에 퍼포먼스가 되는아트랩대전 고동환 전시회고동환 전시회 6개의 벽,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>만화 x 영화 홍콩만화애니메이션전 스케치 at 동대문 DDP 서울전시회 추천현재 동...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미술전시회 김현식 작가 개인전개인전 ‘玄’ 포스팅을 할까 합니다~화장한 10월의 어...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>서울역 맛집 유즈라멘을 추천합니다!유즈라멘은 서울역점에서 시작하여 안국역에 분점을 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>2TV 저녁 생생정보 / 생생정보통맛집오늘 서울 건대 인천 맛집우리의 저녁을 행복하...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>안녕하세요, 하루의 마실입니다.오늘의 포스팅은 대학로/혜화에 위치한 홍대 돈가스 맛...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>유튜브에서 빙수야가 유명해지기 전, 친구가 빙수야를 알려주면서 한 번 가보고 싶다고...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>안녕하세요! 씽푸미니 입니다.  오늘 리뷰할 곳은 스시 오마카세 '스시소라' 입니다...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     [전시회] 비욘더로드: 과몰입형, 출구없는 전시회이머시브 전시로 소문이 자자했던 비...       0\n",
       "1     부천 가볼만한 전시회 심곡천 네모 갤러리에 다녀왔어요부천 가볼만한 전시회심곡천 네모...       0\n",
       "2     관람객이면서 동시에 퍼포먼스가 되는아트랩대전 고동환 전시회고동환 전시회 6개의 벽,...       0\n",
       "3     만화 x 영화 홍콩만화애니메이션전 스케치 at 동대문 DDP 서울전시회 추천현재 동...       0\n",
       "4     미술전시회 김현식 작가 개인전개인전 ‘玄’ 포스팅을 할까 합니다~화장한 10월의 어...       0\n",
       "...                                                 ...     ...\n",
       "3243  서울역 맛집 유즈라멘을 추천합니다!유즈라멘은 서울역점에서 시작하여 안국역에 분점을 ...       5\n",
       "3244  2TV 저녁 생생정보 / 생생정보통맛집오늘 서울 건대 인천 맛집우리의 저녁을 행복하...       5\n",
       "3245  안녕하세요, 하루의 마실입니다.오늘의 포스팅은 대학로/혜화에 위치한 홍대 돈가스 맛...       5\n",
       "3246  유튜브에서 빙수야가 유명해지기 전, 친구가 빙수야를 알려주면서 한 번 가보고 싶다고...       5\n",
       "3247  안녕하세요! 씽푸미니 입니다.  오늘 리뷰할 곳은 스시 오마카세 '스시소라' 입니다...       5\n",
       "\n",
       "[29627 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([nm_df,np_df,nt_df,na_df,nc_df,tf_df])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b8ea128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24467\n"
     ]
    }
   ],
   "source": [
    "#중복된 정보 제거.\n",
    "df.drop_duplicates(subset=['text'],inplace=True)\n",
    "\n",
    "print(df['text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c6f3be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#빈칸인 행 제거.\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df= df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38581480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-044abb49bebb>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text']=df['text'].str.replace(\"[^가-힣 ]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전시회 비욘더로드 과몰입형 출구없는 전시회이머시브 전시로 소문이 자자했던 비욘더로드...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부천 가볼만한 전시회 심곡천 네모 갤러리에 다녀왔어요부천 가볼만한 전시회심곡천 네모...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>관람객이면서 동시에 퍼포먼스가 되는아트랩대전 고동환 전시회고동환 전시회 개의 벽 개...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>만화  영화 홍콩만화애니메이션전 스케치  동대문  서울전시회 추천현재 동대문  배움...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미술전시회 김현식 작가 개인전개인전  포스팅을 할까 합니다화장한 월의 어느날 아이들...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>코로나사태가 발생한지 벌써 약 년째그동안 전시회 페스티벌 등이 엄청 그리웠었죠월 위...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>필립 할스만 점핑 어게인  필립 할스만  점핑 어게인긍정적인 에너지와 도전필립 할스...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>여주 그린베이지소목장개인전시회지난주 금요일에 여주에 일이 있어 갔다가 협회 선생님이...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>캠핑박람회  캠피크  수원감성 캠핑용품 캠핑카 전시회 캠피크  수원인스타 친구소환 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>대전 유성구 이벤트유성국화전시회  즐기기언제나처럼 빵빵한 선물을 가지고 진행하는 유...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  전시회 비욘더로드 과몰입형 출구없는 전시회이머시브 전시로 소문이 자자했던 비욘더로드...       0\n",
       "1  부천 가볼만한 전시회 심곡천 네모 갤러리에 다녀왔어요부천 가볼만한 전시회심곡천 네모...       0\n",
       "2  관람객이면서 동시에 퍼포먼스가 되는아트랩대전 고동환 전시회고동환 전시회 개의 벽 개...       0\n",
       "3  만화  영화 홍콩만화애니메이션전 스케치  동대문  서울전시회 추천현재 동대문  배움...       0\n",
       "4  미술전시회 김현식 작가 개인전개인전  포스팅을 할까 합니다화장한 월의 어느날 아이들...       0\n",
       "5  코로나사태가 발생한지 벌써 약 년째그동안 전시회 페스티벌 등이 엄청 그리웠었죠월 위...       0\n",
       "6  필립 할스만 점핑 어게인  필립 할스만  점핑 어게인긍정적인 에너지와 도전필립 할스...       0\n",
       "7  여주 그린베이지소목장개인전시회지난주 금요일에 여주에 일이 있어 갔다가 협회 선생님이...       0\n",
       "8  캠핑박람회  캠피크  수원감성 캠핑용품 캠핑카 전시회 캠피크  수원인스타 친구소환 ...       0\n",
       "9  대전 유성구 이벤트유성국화전시회  즐기기언제나처럼 빵빵한 선물을 가지고 진행하는 유...       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#한글을 제외한 글자 제거\n",
    "df['text']=df['text'].str.replace(\"[^가-힣 ]\", \"\")\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7f2517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24467\n",
      "text      23\n",
      "target     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#빈칸인 행 제거.\n",
    "import numpy as np\n",
    "df['text'].replace('',np.nan, inplace=True)\n",
    "print(len(df))\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c030c0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24444\n"
     ]
    }
   ],
   "source": [
    "#전체 수 확인\n",
    "df= df.dropna(how='any')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb696b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석에 불필요한 데이터 지정\n",
    "stopwords=['을','는','이가','께서','것','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','에서']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657ce188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석을 한 자료 정제과정\n",
    "mecab = eunjeon.Mecab()\n",
    "import re\n",
    "text=[]\n",
    "for sentence in df['text']:\n",
    "    text.append([word for word in mecab.morphs(sentence)if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "380483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석을 한 자료 정제과정\n",
    "mecab = eunjeon.Mecab()\n",
    "import re\n",
    "train_input=[]\n",
    "for sentence in df['text']:\n",
    "    train_input.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fdbe1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24444\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b397535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_num = 128\n",
    "\n",
    "embedding = FastText(text, vector_size=emb_num, window=12, min_count=5, sg=1)\n",
    "embedding.save(\"fasttext_morph.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e11d7f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('화분', 0.8299668431282043),\n",
       " ('초록', 0.742006242275238),\n",
       " ('푸릇푸릇', 0.7015954256057739),\n",
       " ('꽃나무', 0.68097323179245),\n",
       " ('아기자기', 0.675330400466919),\n",
       " ('꽃식물', 0.6512247920036316),\n",
       " ('화초', 0.6481088399887085),\n",
       " ('가꿔', 0.6465709209442139),\n",
       " ('가꿔진', 0.6442983150482178),\n",
       " ('푸르르', 0.6395153999328613)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_morphs = FastText.load(\"fasttext_morph.model\")\n",
    "model_morphs.wv.most_similar(\"식물\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcbdca35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('요리', 0.7588831186294556),\n",
       " ('요양식', 0.6422492861747742),\n",
       " ('돋울', 0.6318318247795105),\n",
       " ('음식집', 0.6318122744560242),\n",
       " ('식', 0.6308205723762512),\n",
       " ('정말', 0.6195213794708252),\n",
       " ('음식점', 0.6168780326843262),\n",
       " ('메뉴', 0.6128191947937012),\n",
       " ('나오', 0.6119093298912048),\n",
       " ('데', 0.6101112365722656)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_morphs.wv.most_similar(\"음식\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f60cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d3cd580",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"review.txt\"\n",
    "prefix = \"review\"\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b72ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 만나서 반갑습니다\n",
      "['▁안녕하세요', '▁만나서', '▁반갑', '습니다']\n",
      "[2728, 6211, 6282, 29]\n"
     ]
    }
   ],
   "source": [
    "vocab_file = \"review.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "line = \"안녕하세요 만나서 반갑습니다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31e72ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4b9ba20c11b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#형태소 분석을 한 자료 정제과정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtokened_sp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_as_pieces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokened_sp = []\n",
    "#형태소 분석을 한 자료 정제과정\n",
    "for sentence in df['text']:\n",
    "    tokened_sp.append(vocab.encode_as_pieces(sentence ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "754d3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_num = 128\n",
    "\n",
    "embedding = FastText(tokened_sp, vector_size=emb_num, window=10, min_count=2, sg=1)\n",
    "embedding.save(\"fasttext_sp.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2848004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁식물', 0.8120625615119934),\n",
       " ('▁화분', 0.7289825677871704),\n",
       " ('화분', 0.6880204677581787),\n",
       " ('반려', 0.6422896385192871),\n",
       " ('▁식물이', 0.6018108129501343),\n",
       " ('정화식물', 0.5776996612548828),\n",
       " ('▁반려', 0.5761829018592834),\n",
       " ('동물', 0.5665410757064819),\n",
       " ('초록', 0.5616799592971802),\n",
       " ('▁키우기', 0.56104576587677)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sp = FastText.load(\"fasttext_sp.model\")\n",
    "model_sp.wv.most_similar(\"식물\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d110b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a7ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.10.0-cp38-cp38-win_amd64.whl (226.6 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e035791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, dataset, target, tokenizer, fasttextModel, max_len):\n",
    "        self.sentences = []\n",
    "        with trange(len(dataset)) as tr:\n",
    "            for i in tr:\n",
    "                sen = dataset[i]\n",
    "                sen = tokenizer(sen) #토큰화\n",
    "                if len(sen) < max_len:\n",
    "                    sen = sen + (max_len-len(sen)) * [\"\"]\n",
    "                sen = sen[:max_len]\n",
    "                sen = fasttextModel[sen] #임베딩\n",
    "                self.sentences.append(sen)\n",
    "        self.labels = [np.int32(i) for i in target]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i],self.labels[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05fcbb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_target=np.array(df['target'])\n",
    "train_input, test_input, train_target, test_target= train_test_split(\n",
    "train_input, train_target, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1f4a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 21999/21999 [02:56<00:00, 124.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2445/2445 [00:18<00:00, 130.73it/s]\n"
     ]
    }
   ],
   "source": [
    "mecab = eunjeon.Mecab()\n",
    "max_len = 32\n",
    "morphs_train = SentenceDataset(train_input, train_target, mecab.morphs, model_morphs.wv, max_len)\n",
    "morphs_test = SentenceDataset(test_input, test_target, mecab.morphs,model_morphs.wv, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a28a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이어를 주어 학습히기키\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "#최적의 모델을 찾기 위한 모듈\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe1f6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c04bcb21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class '__main__.SentenceDataset'>, <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-20d579cdd3fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmorphs_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    986\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class '__main__.SentenceDataset'>, <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "es=EarlyStopping(monitor='val_loss', mode='min',verbose=1, patience=4)\n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "history= model.fit(morphs_train,train_target, epochs=20, callbacks=[es, mc], batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c7d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(morphs_train, batch_size=batch_size, num_workers=5, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(morphs_test, batch_size=batch_size, num_workers=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86eac1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000026E14180520>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d7a9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "619ffe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size, num_layers = 1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # self.emb = nn.Embedding(num_embeddings = len(vocab), embedding_dim = 128, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
    "                            num_layers = num_layers, batch_first = True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.linear2 = nn.Linear(hidden_size//2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "    \n",
    "        self.fc = nn.Sequential(self.linear, self.dropout, self.relu, self.linear2, self.dropout)\n",
    "        # self.fc = nn.Sequential(self.linear, self.dropout)\n",
    "\n",
    "    def forward(self, x_input):\n",
    "        # x_input = self.emb(x_input)\n",
    "        lstm_out, (h,c) = self.lstm(x_input)\n",
    "        output = self.fc(lstm_out[:,-1,])\n",
    "        \n",
    "        # hidden = torch.cat((h[-2,:,:], h[-1,:,:]), dim = 1)\n",
    "        # output=self.fc(hidden)\n",
    "        # output = self.relu(output)\n",
    "        # output = self.linear2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "emb_num = 128\n",
    "lstm = LSTM(emb_num, 6, 128, 2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.0003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "with trange(epochs) as tr:\n",
    "    for i in tr:\n",
    "        itloss = 0\n",
    "        trainacc = 0\n",
    "        testacc = 0\n",
    "        \n",
    "        lstm.train()\n",
    "        for batch_id, (input, label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input = input.to(device)\n",
    "            label = label.long().to(device)\n",
    "            out = lstm(input)\n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            itloss += loss.cpu().item()\n",
    "            trainacc += calc_accuracy(out,label)\n",
    "\n",
    "\n",
    "        lstm.eval()\n",
    "        for batch_idt, (input, label) in enumerate(test_dataloader):\n",
    "            input = input.to(device)\n",
    "            label = label.long().to(device)\n",
    "            out = lstm(input)\n",
    "            testacc += calc_accuracy(out,label)\n",
    "\n",
    "        tr.set_postfix(trainacc=\"{0:.3f}\".format(trainacc/(batch_id+1)), loss=\"{0:.3f}\".format(itloss/(batch_id+1)),  testacc=\"{0:.3f}\".format(testacc/(batch_idt+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87d49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
